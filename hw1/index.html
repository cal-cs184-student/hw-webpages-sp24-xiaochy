<meta http-equiv='cache-control' content='no-cache'>
<meta http-equiv='expires' content='0'>
<meta http-equiv='pragma' content='no-cache'>
<!DOCTYPE html>
<html>

<head>
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<style>
		img {
			max-width: 600px;
		}
	</style>
</head>

<body>
	<h1><b> CS184 HW1: Rasterizer</b> </h1>
	<h2> <b>Task 1 </b></h2>
	<p><b>1. Walk through </b></p>
	<p> To determine whether each pixel on the frame buffer is inside a given triangle:</p>
	<ul>
		<li>First, since the entire frame buffer is too large, it's too slow to traverse it entirely. Therefore, we
			start
			by calculating the bounding box for each of the three triangles using their vertices.
			Then, we want to check whether each pixel within the bounding box is inside the triangle. We approximate the
			coordinates of the bounding box
			boundaries to integers using the floor function for easier traversal of pixels. Additionally,
			we consider the coordinates of each pixel's midpoint as the coordinates to be evaluated within the function
			to determine whether the pixel is inside the triangle.</li>
		<li>Next, we determine whether the vertices of the given triangle are in clockwise or counterclockwise order. We
			achieve this by calculating the <b>cross product</b> of vector AB and vector AC, where A, B, and C
				represent
				the vertices
				of the triangle.
				If the cross product is negative, it indicates a clockwise order; otherwise, it indicates a
				counterclockwise
				order.</li>
		<li>Furthermore, we use the three-line test. If the vertices are in clockwise order, the result of the
			three-line test should be negative for the pixel to be inside the triangle.
			Conversely, if the vertices are in counterclockwise order, the result of the three-line test should be
			positive for the pixel to be inside the triangle.</li>
		<li>If the pixel is inside the triangle, we fill the given color into the corresponding position of the sample
			buffer where the pixel resides. (In Task 1, as we haven't performed super-sampling yet, the size of the
			frame buffer equals the size of the sample buffer.)</li>
		<li>Finally, in the <code>resolve_to_framebuffer()</code> function, we directly transfer the colors from the
			sample buffer to the <b>rgb_framebuffer_target</b>. This allows the colors to be displayed on the screen.
		</li>
	</ul>
	<p><b>2. Algorithm Efficiency</b> </p>
	<p> Since our algorithm does not traverse the whole frame buffer, but just traverse the bounding box of the
		triangle, our algorithm equals to the one that checks each sample within the bounding box of the triangle.</p>
	<p> <b>3. Image Gallery</b></p>
	<figcaption><b>Rasterize triangle without supersampling</b></figcaption>
	<img src="image_1.png" alt="Rasterize triangle without supersampling">

	<h2> <b>Task 2</b></h2>
	<p> <b>1. Importance and Implementation</b></p>
	<p>As described in lecture, supersampling is an effective antialiasing approach. The basic idea is to render the 
		each pixel in the screen space into several samples, then downsample back by averaging the values of the samples.
		This helps us to make smoother edges of triangles, reduing aliasing errors.
	<ul>
		<li>To implement supersampling, we first resize the frame_buffer to store extra samples inside each pixel. In task 1, 
			sample_buffer has the same size as frame_buffer. For task 2, we have width * height pixels and sample_rate samples 
			inside each pixel, which requires <code>sample_buffer</code>'s size of <code>(width * height * sample_rate)</code>.</li>
		<li>Another change, compared with task 1, is to estiate each pixel's value by averaging the value of samples within 
			the pixel. We compute the average and write each pixel's value into <code>resolve_to_framebuffer</code>.</li></ul>
	<p> <b>2. Results</b></p>
	<style>	
		figure {
			border: 1px #cccccc solid;
			padding: 4px;
			margin: auto;
		}
		figcaption {
			/* background-color: black; */
			/* color: white; */
			font-style: italic;
			padding: 2px;
			text-align: center;
		}
		.column {
			float: left;
			width: 30%;
			padding: 5px;
		}
		.row::after {
			content: "";
			clear: both;
			display: table;
		}
	</style>
	<div class="row">
		<div class="column">
			<img src="task2_rate1.png" alt="Sample rate = 1" style="width:100%">
			<figcaption>sample rate = 1</figcaption>
		</div>
		<div class="column">
			<img src="task2_rate4.png" alt="Sample rate = 4" style="width:100%">
			<figcaption>sample rate = 4</figcaption>
		</div>
		<div class="column">
			<img src="task2_rate16.png" alt="Sample rate = 16" style="width:100%">
			<figcaption>sample rate = 16</figcaption>
		</div>	
	</div>
	In the images provided above, the impact of sample rate on edge smoothness is evident. At a sample rate of 1, discernible 
	jaggies are observed, attributed to marking each pixel inside the triangle with the same color. However, as the sampling 
	rate increases, we sample multiple locations within each pixel, subsequently averaging their values. This results in a 
	noticeable improvement, particularly along the edges, where pixels are no longer assigned uniform values. Instead, they 
	exhibit a smoother and blurrier appearance.

			  
	<h2> <b>Task 3</b></h2>
	<p>I tried to make the robot cheer up by doing the rotation to his arms and legs. </p>
	<figcaption><b>cheer-up robot</b></figcaption>
	<img src="image_2.png" alt="cheer-up robot">
	
	<h2> <b>Task 4</b></h2>
	<p> <b>1. Illustration of Barycentric Coordinates</b></p>
	<svg xmlns="http://www.w3.org/2000/svg" width="200" height="200">

		<!-- Define a linear gradient -->
		<defs>
		  <linearGradient id="gradient" x1="0%" y1="0%" x2="100%" y2="100%">
			<stop offset="0%" style="stop-color: red; stop-opacity: 1" />
			<stop offset="50%" style="stop-color: green; stop-opacity: 1" />
			<stop offset="100%" style="stop-color: blue; stop-opacity: 1" />
		  </linearGradient>
		</defs>
	
		<!-- Create an equilateral triangle with the blended gradient -->
		<polygon points="100,10 10,190 190,190" style="fill: url(#gradient);" />
	
	</svg>
	<p>The plot above illustrates the functioning of barycentric coordinates. Assigning red, green, 
		and blue to the three vertices of the triangle respectively, the colors inside the triangle 
		result from a blend of these vertex colors. The color at each sample point is calculated 
		based on its barycentric coordinate: \(C_p = \alpha C_A + \beta C_B + \gamma C_C \). \(\alpha,
		\beta, \gamma\) are obtained based on the proportional distances, and they linearly interpolate
		values at vertices.</p>

	<h2> <b>Task 5 </b></h2>
	<p><b>1. Pixel Sampling</b></p>
	<ul>
		<li>Firstly, given the coordinates of the three vertices of the triangle on the frame buffer and the coordinates
			of an internal point of the triangle, we can calculate the Barycentric coordinates: \(\alpha\),\(\beta\),
			\(\gamma\) = 1 -
			\(\alpha\) - \(\beta\). </li>
		<li>Secondly, knowing the corresponding coordinates of the three vertices of the triangle on the texture, we can
			utilize the previously calculated \(\alpha\), \(\beta\), \(\gamma\) to calculate the coordinates of the
			internal point
			of the triangle on the texture using the Barycentric formula. </li>
		<li>Since the mapping coordinates on the texture may not be integers, we cannot directly obtain the color
			corresponding to the sample. Hence, we have two methods: <code>sample_nearest()</code> and
			<code>sample_bilinear()</code> to obtain the color corresponding to the sample.
		</li>
		<li> <b>Two sampling methods</b>
			<ul>
				<li><code>sample_nearest()</code>: This means we will find the nearest vertex on the texture to the
					sample texture coordinate and assign the color of that vertex to our sample.</li>
				<li><code>sample_bilinear()</code>: This means we will find the four nearest vertices on the texture to
					the sample texture coordinate and use trilinear interpolation to calculate the color of the sample.
				</li>
			</ul>
		</li>
	</ul>
	<p><b>2. Image Gallery</b></p>
	<figcaption><b>Nearest Sampling + Sampling Rate = 1</b></figcaption>
	<img src="image_3.png" alt="Nearest Sampling + Sampling Rate = 1">
	<figcaption><b>Nearest Sampling + Sampling Rate = 16</b></figcaption>
	<img src="image_4.png" alt="Nearest Sampling + Sampling Rate = 16">
	<figcaption><b>Bilinear Sampling + Sampling Rate = 1</b></figcaption>
	<img src="image_5.png" alt="Bilinear Sampling + Sampling Rate = 1">
	<figcaption><b>Bilinear Sampling + Sampling Rate = 16</b></figcaption>
	<img src="image_6.png" alt="Bilinear Sampling + Sampling Rate = 16">
	<p><b>3. Difference between two sampling methods</b></p>
	<ul>
		<li>When the sample rate is low, there will be a large difference between those two methods and we should use
			the bilinear sampling method. Since the number of samples we have is small, we need bilinear sampling to
			make use of the colors of other points on the texture to make the image seem smooth. If we only make use of
			the nearest point on the texture, the image may look sharp.</li>
		<li>When the sample rate is high, we can use either bilinear sampling or nearest sampling. Since the number of
			samples we have is large, even if each sample is assigned with the color value nearest to it, it will still
			create a smooth vision effect.</li>
	</ul>

</body>

</html>