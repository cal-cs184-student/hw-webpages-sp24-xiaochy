<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <style>
    body {
      background-color: white;
      padding: 100px;
      width: 1000px;
      margin: auto;
      text-align: left;
      font-weight: 300;
      font-family: 'Open Sans', sans-serif;
      color: #121212;
    }

    h1,
    h2,
    h3,
    h4 {
      font-family: 'Source Sans Pro', sans-serif;
    }

    kbd {
      color: #121212;
    }
  </style>
  <title>CS 184 Path Tracer</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

</head>


<body>

  <h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
  <h1 align="middle">Project 3-1: Path Tracer</h1>
  <h2 align="middle">Chuyang Xiao, Claire Fang</h2>

  <!-- Add Website URL
  <h2 align="middle">Website URL: <a href="TODO">TODO</a></h2>

  <br><br>


  <div align="center">
    <table style="width=100%">
      <tr>
        <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
    </table>
  </div>

  <p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features
    to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for
    instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file
    names appropriately.</p>
  <o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of
    work which showcases your understanding of relevant concepts through both mesh images as well as written
    explanations about what you did to complete each part of the assignment. Try to be as clear and organized as
    possible when writing about your own output files or extensions to the assignment. We want to understand what you've
    achieved and how you've done it!</p>
    <p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


    <p>Here are a few problems students have encountered in the past. Test your website on the instructional machines
      early!</p>
    <ul>
      <li>Your main report page should be called index.html.</li>
      <li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
      <li>Use only <em>relative</em> paths to files, such as
        <pre>"./images/image.jpg"</pre>
        Do <em>NOT</em> use absolute paths, such as
        <pre>"/Users/student/Desktop/image.jpg"</pre>
      </li>
      <li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional
        machines), capitalization matters.
        <pre>.png != .jpeg != .jpg != .JPG</pre>
      </li>
      <li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this
        please see this tutorial: <a
          href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
      <li>And again, test your website on the instructional machines early!</li>
    </ul>


    <p>Here is an example of how to include a simple formula:</p>
    <p align="middle">
    <pre align="middle">a^2 + b^2 = c^2</pre>
    </p>
    <p>or, alternatively, you can include an SVG image of a LaTex formula.</p> -->

  <div>
      <h2 align="middle">Overview</h2>
      <p>
        In this assignment, we embark on implementing a physically-based renderer utilizing the path tracing algorithm covered in 
        lectures. To provide clarity, our implementation includes several crucial components: random ray generation, ray-scene 
        intersection techniques encompassing primitive-ray intersection, bounding box ray intersection, and BVH-ray intersection, as 
        well as direct and indirect illumination, employing Monte Carlo Estimation. Additionally, we integrate optimization techniques 
        such as Russian Roulette and adaptive sampling to enhance efficiency and quality within the renderer.
      </p>
      <br>

      <h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
      <!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

      <h3>
        Walk through the ray generation and primitive intersection parts of the rendering pipeline.
      </h3>
      <p>
        <li>Ray Generation: Transform the normalized image coordinates to the camera space, generate a ray in the camera
          space and then transform it into a ray in the world space.
        <li>Firstly, since we want to determine the color for each pixel on the image. We generate num_samples rays for each
          pixel.
          we get its bottom-left coordinate and plus the sample vector \(\in [0,1]*[0,1]\) and then divided it by the
          image width and height respectively to get the normalized coordinates.
        </li>
        <li>Secondly, we transform the normalized coordinates (x, y) we get in the image space into the
          camera space by using the formula: \((x_c,y_c,z_c) = (\tan(hFov*(x - 0.5)), tan(vFov*(y - 0.5)), -1)\), where $hFov$ and $vFov$
          should be in radian.
        </li>
        <li>Thirdly, we use camera-to-world transform matrix to get the generated ray in the world space. We
          normalize the word-space ray.</li>
        <li>Finally, we set min_t and max_t of the ray as nClip and fClip, since we consider everything that lies
          outside these two clipping planes invisible to the camera.</li>
        </li>
        <li>Primitive Intersection: Test whether there is an intersection between the input ray and the input triangle
          or sphere surface.
        </li>
      </p>
      <br>

      <h3>
        Explain the triangle intersection algorithm you implemented in your own words.
      </h3>
      <p>
        <li>Ray-Triangle Intersection:
          We use <b>Moller Trumbore Algorithm</b> to implement ray-triangle intersection.
        <li>Firstly, we represent ray \(r(t) = O + tD\) and the point in the triangle as \(P = \alpha P0+\beta P1+\gamma
          P2\), where P0,P1,P2 are the vectors of the triangle. We substitute
          \(\alpha, \beta, \gamma\) with \((1-b1-b2), b1, b2\). After that, we let the two right sides equal and get a
          equation \(Mx = b\) where x is (t,b1,b2), which can be solved from this linear equation.
          If \(t \geq 0, b1, b2, 1-b1-b2 \in [0,1]\), we say the ray is intersected with the triangle.
        </li>
        </li>
      </p>
      <br>

      <h3>
        Show images with normal shading for a few small .dae files.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="./part1/banana.png" align="middle" width="400px" />
              <figcaption>banana.dae</figcaption>
            </td>
            <td>
              <img src=".\part1\CBempty.png" align="middle" width="400px" />
              <figcaption>CBempty.dae</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src=".\part1\cow.png" align="middle" width="400px" />
              <figcaption>cow.dae</figcaption>
            </td>
            <td>
              <img src=".\part1\teapot.png" align="middle" width="400px" />
              <figcaption>teapot.dae</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>


      <h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
      <!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

      <h3>
        Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
      </h3>
      <p>
        <li>
          When constructing the BVH, we choose the axis having the greatest extent in the current round of recursion, splitting
          the primitives at the midpoint of the bounding box on this axis. This helps us divide the primitives more evenly, avoiding
          infinite recursion caused by distributing all primitives to one side.
        </li>
        <li>
          After selecting the proper axis to divide, we sort the primitives in place by the primitive's bounding box midpoint value at that
          axis.
        </li>
        <li>
          Next, we find the midpoint index of the sorted list of primitives. We build the left and right node by recursively calling the 
          function itself. For the left node, we pass in the primitives from start to midpoint in the sorted list; for the right node, we 
          pass in the remained half of the list. 
        </li>
        <li>
          With BVH construction, we now check the intersections more efficiently: we look into the primitives inside a node and update the 
          corresponding values of a ray only when the ray intersects the node. 
        </li>
        </p>

      <h3>
        Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part2/beast.png" align="middle" width="400px" />
              <figcaption>beast.dae</figcaption>
            </td>
            <td>
              <img src="part2/maxplank.png" align="middle" width="400px" />
              <figcaption>maxplank.dae</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part2/cblucy.png" align="middle" width="400px" />
              <figcaption>CBlucy.dae</figcaption>
            </td>
            <td>
              <img src="part2/dragon.png" align="middle" width="400px" />
              <figcaption>dragon.dae</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>

      <h3>
        Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration.
        Present your results in a one-paragraph analysis.
      </h3>
      <li>
        For <code>cow.daw</code> with 5856 primitives, we reduce the rendering time from 14.8433s to 0.0705s.
      </li>
      <li>
        For <code>CBlucy.daw</code> with 133796 primitives, we reduce the rendering time from 390.442s to 0.0508s.
      </li>
      From the two examples above, we observe that BVH significantly accelerates the rendering process, especially for those 
      with a number of primitives. Instead of checking intersection for every single primitive, BVH optimizes the process 
      by dividing the primitives into nodes and checking only the primitives inside the node whose bouding box intersects
      the ray. Therefore, we can skip a bunch of primitives, which saves the time.
      <p>
        
      </p>
      <br>

      <h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
      <!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

      <h3>
        Walk through both implementations of the direct lighting function.
      </h3>
      <p>
        1. Uniform Hemisphere Sampling
        <br>
        This method samples incoming directions uniformly inside a hemisphere. We back trace those directions from the hit point
        and check whether they encounter any light source. Below is a step-by-step instrcution:
        <ul>
        <li>
          We first find the hit point based on the intersection between a ray from the camera and something in the scene. Once we find
          such hit point, we generate random incoming ray directions by uniformly sampling inside a hemisphere.
        </li>
        <li>
          For each random direction, we create a new ray going from hit point in the sampled direction. 
        </li>
        <li>
          If this new ray intersects the light source, we estimate the amount of light (from the single ray) arriving at the hit point 
          by the reflection equation $\frac{f(\omega_i \rightarrow \omega_o) L_i(p, \omega_i) cos\theta_i}{P(\omega_i)}$. $P(\omega_i)$ 
          is the probability of getting that sample. In uniform hemisphere sampling, each direction has the same probability of being chosen, 
          consequently $P(\omega_i) = \frac{1}{2\pi}$.
        </li>
        <li>Once we get all samples, we eatimate the total amount of light arriving at the hit point by using a Monte Carlo Estimator: 
          $\frac{1}{N}\sum_{i = 1}^{N}\frac{f(\omega_i \rightarrow \omega_o) L_i(p, \omega_i) cos\theta_i}{P(\omega_i)}$, where $N$ is 
          the number of samples we take.
        </li>
        </ul>
        2. Importance Sampling Lights
        <br>
        The general idea of importance sampling is the same as the uniform hemisphere sampling, except that now we only generate samples of
        directions of incoming light in the direction of the light sources.
        <ul>
          <li>
            We iterate over the light sources, sampling incoming light directions between the hit point and every light source. If the light source 
            is a point light source, we only sample once to save time (since all samples for a point light source go to the same direction).
          </li>
          <li>
            For every sampled direction, we check whether there is any object between the hit point and the light source. If not, we estimate 
            the amount of light using the same approach illustrated in uniform hemisphere sampling.
          </li>
          </ul>
      </p>

      <h3>
        Show some images rendered with both implementations of the direct lighting function.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <!-- Header -->
          <tr align="center">
            <th>
              <b>Uniform Hemisphere Sampling</b>
            </th>
            <th>
              <b>Light Sampling</b>
            </th>
          </tr>
          <br>
          <tr align="center">
            <td>
              <img src="part3/CBbunny_H_16_8.png" align="middle" width="400px" />
              <figcaption>CBbunny.dae (16 rays per pixel + 8 samples per light)</figcaption>
            </td>
            <td>
              <img src="part3/bunny_16_8.png" align="middle" width="400px" />
              <figcaption>CBbunny.dae (16 rays per pixel + 8 samples per light)</figcaption>
            </td>
          </tr>
          <br>
          <tr align="center">
            <td>
              <img src="part3/CBbunny_H_64_32.png" align="middle" width="400px" />
              <figcaption>CBbunny.dae (64 rays per pixel + 32 samples per light)</figcaption>
            </td>
            <td>
              <img src="part3/bunny_64_32.png" align="middle" width="400px" />
              <figcaption>CBbunny.dae (64 rays per pixel + 32 samples per light)</figcaption>
            </td>
          </tr>
          <br>
        </table>
      </div>
      <br>

      <h3>
        Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b>
        when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using
        light sampling, <b>not</b> uniform hemisphere sampling.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part3/bunny_1_1.png" align="middle" width="400px" />
              <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part3/bunny_1_4.png" align="middle" width="400px" />
              <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part3/bunny_1_16.png" align="middle" width="400px" />
              <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part3/bunny_1_64.png" align="middle" width="400px" />
              <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <p>
        With few light rays, the shadow is shattered, and we can see the noisy points around. As we render with higher number of light rays, 
        we find that the shadown under the bunny become "softer."
      </p>
      <br>

      <h3>
        Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
      </h3>
      <p>
       When using the same parameters, importance sampling converges faster than uniform hemisphere sampling does (the image with 64 rays per pixel 
       and 32 samples per light already looks pretty good for importance sampling, but still quite noisy for uniform hemisphere sampling). The reason 
       is that uniform hemisphere sampling take random samples in every direction, while importance sampling only focuses on directions between hit point and 
       the light sources and it samples the point light sources only once. This difference between the two sampling methods also lead to the 
       fact that the results from uniform hemisphere sampling is more noisy than that from importance sampling.
      </p>
      <br>


      <h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
      <!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

      <h3>
        Walk through your implementation of the indirect lighting function.
      </h3>
      <p>
        <li>
          Firstly, when generating ray from pixels in <code>raytrace_pixel(size_t x, size_t y)</code>, we set the
          depth of each ray as max_ray_depth.
        </li>
        <li>
          Secondly, in <code>raytrace_pixel(size_t x, size_t y)</code>, we call
          <code>est_radiance_global_illumination(const Ray &r)</code> for each sample ray to calculate its radiance on
          this pixel.
        </li>
        <li>
          Next, we divide into two cases in <code>est_radiance_global_illumination(const Ray &r)</code>: <code>isAccumBounces = true</code>
          and <code>isAccumBounces = false</code>. If it is true, the method returns
          <code>zero_bounce_radiance(r, isect) + at_least_one_bounce_radiance(r, isect)</code>. Otherwise, the method 
          returns <code>at_least_one_bounce_radiance(r, isect)</code>, only estimating the radience at the required level.
          If <code>ray depth == 0,</code>, we return <code>zero_bounce_radiance(r, isect)</code> directly.
        </li>
        <li>
          In <code>at_least_one_bounce_radiance(const Ray &r,const Intersection &isect)</code>, we also need to check 
          the value of <code>isAccumBounces</code>. If it is true, the method would cumulatively add the direct illumination with 
          the indirect illumination on this intersection until it reaches the ray's <code>max_depth</code>. However, for
          <code>isAccumBounces = false</code>, we only add the direct illumination once when the ray achieves its max_ray_depth,
          which means we only estimate the amount of light arriving at the intersection with <code>max_depth</code> bounces.
        </li>
        <li>
          In order to avoid bias resulted from forcing termination after <code>max_depths</code> bounces as well as to reduce the 
          rendering time, we implement Russian Roulette, which provides us an unbiased method of random termination. Our termination 
          probability is 0.65, and we use a random <code>coin_flip</code> to determine whether we terminate or not (if coin_flip \(\geq\) 0.65, 
          the ray tracing algorithm stops).
        </li>
      </p>
      <br>

      <h3>
        Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part4_2/lucy.png" align="middle" width="400px" />
              <figcaption>CBlucy.dae with global illumination</figcaption>
            </td>
            <td>
              <img src="part4_2\gems.png" align="middle" width="400px" />
              <figcaption>CBgems.dae with global illumination</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>

      <h3>
        Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination.
        Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to
        generate these views.)
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part4_3/bunny_direct.png" align="middle" width="400px" />
              <figcaption>Only direct illumination (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part4_3/bunny_indirect_only.png" align="middle" width="400px" />
              <figcaption>Only indirect illumination (CBbunny.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>
      <p>
        YOUR EXPLANATION GOES HERE
      </p>
      <br>

      <h3>
        For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag),
        and isAccumBounces=false. Explain in your writeup what you see for the 2nd and 3rd bounce of light, and how it
        contributes to the quality of the rendered image compared to rasterization. Use 1024 samples per pixel.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="./part4_4/bunny_m0_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 0, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src=".\part4_4\bunny_m1_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 1, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src=".\part4_4\bunny_m2_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 2, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src=".\part4_4\bunny_m3_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 3, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src=".\part4_4\bunny_m4_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 4, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src=".\part4_4\bunny_m5_0.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 5, isAccumBounces = false (CBbunny.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>
      <p>
        The second bounce lights up the places without light before. The ceiling, which is dark in zero and one bounce,
        is now bright. The third bounce helps further improve the details of light and shadow in the environment.
        <li>The second bounce helps to fill in areas of the scene that may not receive direct light, resulting in more
          realistic and natural-looking images. It enhances the overall lighting distribution and creates a sense of
          depth and atmosphere.</li>
        <li>The third bounce helps to smooth out the indirect lighting and reduce noise in the final rendered image,
          resulting in a higher quality and more visually pleasing result.</li>
        Compared to rasterization, rather than approximating the indirect illumination, we simulate the real light paths
        in tracing light, which makes the rendered image more realistic and less noisy.
      </p>
      <br>

      <h3>
        For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4 and 5 (the -m flag). Use 1024
        samples per pixel.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part4_5/bunny_m0_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src=".\part4_5\bunny_m1_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src=".\part4_5\bunny_m2_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="./part4_5/bunny_m3_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
            </td>
            <td>
          </tr>
          <tr align="center">
            <td>
              <img src=".\part4_5\bunny_m4_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src=".\part4_5\bunny_m5_1.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>
      <p>
        We can see that after the second bounce, the image looks pretty good. The higher bounces help further refine
        the details of shadowing, which makes the image even more realistic. And with the higher bounces added on, the
        image becomes brighter and brighter.
      </p>
      <br>

      <h3>
        For CBbunny.dae, output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2, 3, 4, and 100(the -m
        flag). Use 1024 samples per pixel.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part4_6/bunny_m0_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 0 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part4_6/bunny_m1_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 1 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part4_6/bunny_m2_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 2 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part4_6/bunny_m3_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 3 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part4_6/bunny_m4_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 4 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part4_6/bunny_m100_1_rr.png" align="middle" width="400px" />
              <figcaption>max_ray_depth = 100 with Russian Roulette(CBbunny.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>
      <p>
        The rendered images with Russian Roulette are similar to what we got from previous parts. However, the rendering
        time reduces.
      </p>
      <br>

      <h3>
        Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8,
        16, 64, and 1024. Use 4 light rays.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part4_7/dragon_1.png" align="middle" width="400px" />
              <figcaption>1 sample per pixel (CBdragon.dae)</figcaption>
            </td>
            <td>
              <img src="part4_7/dragon_2.png" align="middle" width="400px" />
              <figcaption>2 samples per pixel (CBdragon.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part4_7/dragon_4.png" align="middle" width="400px" />
              <figcaption>4 samples per pixel (CBdragon.dae)</figcaption>
            </td>
            <td>
              <img src="part4_7/dragon_8.png" align="middle" width="400px" />
              <figcaption>8 samples per pixel (CBdragon.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part4_7/dragon_16.png" align="middle" width="400px" />
              <figcaption>16 samples per pixel (CBdragon.dae)</figcaption>
            </td>
            <td>
              <img src="part4_7/dragon_64.png" align="middle" width="400px" />
              <figcaption>64 samples per pixel (CBdragon.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part4_7/dragon_1024.png" align="middle" width="400px" />
              <figcaption>1024 samples per pixel (CBdragon.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>
      <p>
        With the number of samples per pixel increasing, the rendered image becomes less and less noisy.
      </p>
      <br>


      <h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
      <!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

      <h3>
        Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
      </h3>
      <p>
        Adaptive Sampling: Adaptive sampling tries to avoid the problem of using a fixed (high) number of samples per
        pixel, by concentrating the samples in the more difficult parts of the image, which means to stop sampling rays
        from one pixel if the illumination of this pixel is already converged.
        <li>Implementation: We keep track of the average and the variance of the illumination of each pixel. If the
          variable indicating convergence \(I = 1.96*\frac{\sigma}{\sqrt{n}} \leq maxTolerance*\mu\) where maxTolerance
          = 0.05 and n is the number of samples so far, we say that this pixel is converged. Therefore, we will stop
          sampling from this pixel.</li>
      </p>
      <br>

      <h3>
        Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with
        clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate
        image, which shows your how your adaptive sampling changes depending on which part of the image you are
        rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
      </h3>
      <!-- Example of including multiple figures -->
      <div align="middle">
        <table style="width:100%">
          <tr align="center">
            <td>
              <img src="part5/bunny.png" align="middle" width="400px" />
              <figcaption>Rendered image (CBbunny.dae)</figcaption>
            </td>
            <td>
              <img src="part5/bunny_rate.png" align="middle" width="400px" />
              <figcaption>Sample rate image (CBbunny.dae)</figcaption>
            </td>
          </tr>
          <tr align="center">
            <td>
              <img src="part5/dragon.png" align="middle" width="400px" />
              <figcaption>Rendered image (CBdragon.dae)</figcaption>
            </td>
            <td>
              <img src="part5/dragon_rate.png" align="middle" width="400px" />
              <figcaption>Sample rate image (CBdragon.dae)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br>


</body>

</html>